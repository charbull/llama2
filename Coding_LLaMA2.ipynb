{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f113e7ecea742e99bd85ec602a879fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_3ad5084f1081442e9e771d634bf6da82"
          }
        },
        "7211eafe6ff64820bcb3a759d3a1c4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3004e37ca6104267bd6fa9414076fe00",
            "placeholder": "​",
            "style": "IPY_MODEL_41740a1063f044e9baf348a91d10abd5",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ec5ed8b977c64e67a378a54363f563ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4de431debbe14a9097ed121e1889adbe",
            "placeholder": "​",
            "style": "IPY_MODEL_76f7f3e5913d435c9b6e04e1117c1ca9",
            "value": ""
          }
        },
        "f81961f498fe405fbfedd0f70a5c585f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_6eeb23264d6e41ada03916d4b57245aa",
            "style": "IPY_MODEL_21b6e00c4a2545f380ffb5a07f233dc7",
            "value": true
          }
        },
        "46bbe23c3de643f4afa9a52606ea2014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_36ae0db17eab43a3ba172f7b8325ac6e",
            "style": "IPY_MODEL_6b0e90a8bcac4febaf5617e0f39701c5",
            "tooltip": ""
          }
        },
        "c229d742ba0249d3a9d94a8983634835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a792e0d21a5d4cf293d53dcef6f36f94",
            "placeholder": "​",
            "style": "IPY_MODEL_5e6e5ae4bdfa48d3b265072e9f1ca5c3",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "3ad5084f1081442e9e771d634bf6da82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3004e37ca6104267bd6fa9414076fe00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41740a1063f044e9baf348a91d10abd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4de431debbe14a9097ed121e1889adbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f7f3e5913d435c9b6e04e1117c1ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eeb23264d6e41ada03916d4b57245aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b6e00c4a2545f380ffb5a07f233dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36ae0db17eab43a3ba172f7b8325ac6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0e90a8bcac4febaf5617e0f39701c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a792e0d21a5d4cf293d53dcef6f36f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6e5ae4bdfa48d3b265072e9f1ca5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6175e2381b9b4a5ea97b160495dcb9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f2a9f8a57a4d33915a168089a8bdf7",
            "placeholder": "​",
            "style": "IPY_MODEL_f31ecc7404704dde930d2895ad667667",
            "value": "Connecting..."
          }
        },
        "50f2a9f8a57a4d33915a168089a8bdf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f31ecc7404704dde930d2895ad667667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Background reading\n",
        "\n",
        "* This colab is made by following [Coding LLaMA2 from scratch in Pytorch](https://youtu.be/oM4VmoabDAI?si=wqO0DodGhpvQjZK4)\n",
        "  * [Slides](https://github.com/hkproj/pytorch-llama/blob/main/Slides.pdf)\n",
        "  * [Code](https://github.com/hkproj/pytorch-llama)\n",
        "* Rotary embedding: the following video introduces the topic simply: [rotary](https://youtu.be/o29P0Kpobz0?si=PNAqtmp33uJ2Gozv)\n",
        "* KV Cache in transformers [KV Cache](https://youtu.be/80bIUggRJf4?si=_rE35Q9BMMA9Ge31)"
      ],
      "metadata": {
        "id": "IX6f5O0ObUHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n"
      ],
      "metadata": {
        "id": "7fSwwM-jQZHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "import sentencepiece\n",
        "import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "@dataclass\n",
        "class ModelArgs:\n",
        "  dim: int = 4096 # embeddings dimension?\n",
        "  n_layers: int = 32\n",
        "  n_heads: int = 32 # Number of heads for the queries\n",
        "  n_kv_heads: Optional[int] = None # Number of heads for the k and v\n",
        "  vocab_size: int = -1 # This will be set when we load the tokenizer\n",
        "  # hidden dimension of the FFN layer its to compensate for the grouped query attention\n",
        "  multiple_of : int = 256\n",
        "  ffn_dim_multiplier: Optional[float] = None\n",
        "  # we will see why we need it\n",
        "  norm_eps: float = 1e-5\n",
        "  ## needed for KV Cache\n",
        "  max_batch_size: int = 32\n",
        "  max_seq_len: int = 2048\n",
        "\n",
        "  device: str = None\n",
        "\n",
        "\n",
        "def _precompute_theta_pos_frequencies(head_dim: int, seq_len: int, device: str, theta: float=10000.0) -> torch.Tensor:\n",
        "  \"\"\"precomputed theta frequencies for rotary embeddings.\"\"\"\n",
        "  # as written in the paper\n",
        "  assert head_dim % 2 == 0, \"head_dim must be divisible by 2 for this to work\"\n",
        "  # Build the theta parameters according to the formula\n",
        "  # theta_i = 10000 ^ (-2(i-1)/dim) for i = [1, 2, ... dim/2]\n",
        "  # Shape: (Head_dim /2)\n",
        "  theta_numerator = torch.arange(0, head_dim, 2).float()\n",
        "  # Shape: (head_dim/2)\n",
        "  theta = 1.0 / (theta ** (theta_numerator / head_dim)).to(device)\n",
        "  # construct the posiitons (the \"m\" parameters)\n",
        "  # Shape: (Seq_Len)\n",
        "  m = torch.arrange(seq_len, device=device)\n",
        "  # Multiply each theta by each position using the outer product.\n",
        "  # Shape: (Seq_len) outer_product * (Head_dim/2) -> (seq_len, head_dim/2)\n",
        "  freqs = torch.outer(m, theta).float()\n",
        "  # we can compute complex numbers in the complex form c= R * exp(i * m * theta), where R = 1 as follows:\n",
        "  # (seq_len, head_dim/2) -> (seq_len, head_dim/2)\n",
        "  freqs_complex = torch.polar(torch.ones_like(freqs), freqs)\n",
        "  return freqs_complex\n",
        "\n",
        "def apply_rotary_pos_embeddings(x: torch.Tensor, freqs_complex: torch.Tensor, device: str) -> torch.Tensor:\n",
        "  \"\"\"Apply rotary positional embeddings to a tensor.\"\"\"\n",
        "  # (B, Seq_len, H, Head_dim) -> (B, seq_len, H, Head_dim/2)\n",
        "  x_complex = torch.view_as_complex(x.float().reshape(x.shape[0], x.shape[1], -1, 2))\n",
        "  # (Seq_len, Head_dim/2 ) -> (1, Seq_len, 1, Head_dim/2)\n",
        "  freqs_complex = freqs_complex.unsqueeze(0).unsqueeze(2)\n",
        "  # (B, Seq_len, H, Head_dim/2) * (1, Seq_len, 1, Head_dim/2) = (B, Seq_len, H, Head_dim/2)\n",
        "  x_rotated = x_complex * freqs_complex\n",
        "  # (B, Seq_len, H, Head_dim/2) -> (B, Seq_len, H, Head_dim/2, 2)\n",
        "  x_out = torch.view_as_real(x_rotated)\n",
        "  # (B, Seq_len, H, Head_dim/2, 2) -> (B, Seq_len, H, Head_dim)\n",
        "  x_out = x_out.reshape(*x.shape)\n",
        "  return x_out.type_as(x).to(device)\n",
        "\n",
        "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
        "  \"\"\"Repeat the values n_rep times.\"\"\"\n",
        "  batch_size, seq_len, n_kv_heads, head_dim = x.shape\n",
        "  if n_rep == 1:\n",
        "    return x\n",
        "  else:\n",
        "    return (\n",
        "      # (B, seq_len, N_kv_heads, 1, heads_dim)\n",
        "      x[:, :, :, None, :].expand(batch_size, seq_len, n_kv_heads, n_rep, head_dim)\n",
        "      .reshape(batch_size, seq_len, n_kv_heads * n_rep, head_dim)\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "  def __init__(self, dim: int, eps: float = 1e-6) -> None:\n",
        "    super().__init__()\n",
        "    # epsilon to avoid a division by zero\n",
        "    self.eps = eps\n",
        "    # the gamma parameter\n",
        "    self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "  def _norm(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    # (B, seq_len, dim) * (B, seq_len, 1) -> (B, seq_len, Dim)\n",
        "    # rsqrt: 1/sqrt(x)\n",
        "    return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    # (Dim) * (B, Seq_len, Dim) = (B, Seq_len, Dim)\n",
        "    return self.weight * self._norm(x.float()).type_as(x)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, args: ModelArgs) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    hidden_dim = 4 * args.dim\n",
        "    hidden_dim = int(2 * hidden_dim / 3)\n",
        "    if args.ffn_dim_multiplier is not None:\n",
        "      hidden_dim = int(args.ffn_dim_multiplier * hidden_dim)\n",
        "    # Round the hidden_dim to the nearest multiple of the multiple_of parameter\n",
        "    hidden_dim = args.multiple_of * ((hidden_dim + args.multiple_of - 1) // args.multiple_of)\n",
        "\n",
        "    self.w1 = nn.Linear(args.dim, hidden_dim, bias=False)\n",
        "    self.w2 = nn.Linear(hidden_dim, args.dim, bias=False)\n",
        "    self.w3 = nn.Linear(args.dim, hidden_dim, bias=False)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    swish = F.silu(self.w1(x))\n",
        "    x_V = self.w3(x)\n",
        "    x = swish * x_V\n",
        "    x = self.w2(x)\n",
        "    return x\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "  # Only used for inference\n",
        "  def __init__(self, args: ModelArgs) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # code simplified, the parallelisation is removed\n",
        "    # Number of heads for the key and the value\n",
        "    self.n_kv_heads = args.n_kv_heads if args.n_kv_heads is not None else args.n_heads\n",
        "    # number of heads for the query\n",
        "    self.n_heads_q = args.n_heads\n",
        "    # how many times the heads of the keys and values should be repeated to match the head of the queries\n",
        "    self.n_rep = self.n_heads_q // self.n_kv_heads\n",
        "    # the part of the embedding that will be vizualized by each head\n",
        "    # the dimension of each head\n",
        "    self.head_dim = args.dim // args.n_heads\n",
        "\n",
        "    self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
        "    self.wk = nn.Linear(args.dim, args.n_kv_heads * self.head_dim, bias=False)\n",
        "    self.wv = nn.Linear(args.dim, args.n_kv_heads * self.head_dim, bias=False)\n",
        "    self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
        "\n",
        "    self.cache_k = torch.zeros((args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim))\n",
        "    self.cache_v = torch.zeros((args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim))\n",
        "\n",
        "  def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor)  -> torch.Tensor:\n",
        "    batch_size, seq_len, _ = x.shape #(B, 1, dim)\n",
        "    # Apply the Wq, Wk, and Wv matrices to queries, keys, and values\n",
        "    # (B, 1, dim) -> (B, 1, H_Q* Head_dim)\n",
        "    xq = self.wq(x)\n",
        "    # (B, 1, dim) -> (B, 1, H_KV * Head_dim)\n",
        "    xk = self.wk(x)\n",
        "    xv = self.wv(x)\n",
        "\n",
        "    # Split into the various heads for each Q, K, V\n",
        "    # (B, 1, H_Q * Head_dim) -> (B, 1, H_Q, Head_dim)\n",
        "    xq = xq.view(batch_size, seq_len, self.n_heads_q, self.head_dim)\n",
        "    # (B, 1, H_KV * Head_dim) -> (B, 1, H_KV, Head_dim)\n",
        "    xk = xk.view(batch_size, seq_len, self.n_kv_heads, self.head_dim)\n",
        "    xv = xv.view(batch_size, seq_len, self.n_kv_heads, self.head_dim)\n",
        "\n",
        "    # Apply rotary positional encodings on Q, K but not V\n",
        "    xq = apply_rotary_pos_embeddings(xq, freqs_complex, x.device)\n",
        "    xk = apply_rotary_pos_embeddings(xk, freqs_complex, x.device)\n",
        "\n",
        "    # Replace the entry in the cache for this token\n",
        "    self.cache_k[:batch_size, start_pos:start_pos + seq_len] = xk\n",
        "    self.cache_v[:batch_size, start_pos:start_pos + seq_len] = xv\n",
        "\n",
        "    # Retrieve all the cached keys and values for the pos\n",
        "    # (B, seq_len_kv, , H_KV, Head_dim)\n",
        "    keys = self.cache_k[:batch_size, 0:start_pos+seq_len]\n",
        "    values = self.cache_v[:batch_size, 0:start_pos+seq_len]\n",
        "\n",
        "    # Repeat the heads of the K and V to reach the number of heads of the queries to treat it as a vanilla multihead\n",
        "    keys = repeat_kv(keys, self.n_rep)\n",
        "    values = repeat_kv(values, self.n_rep)\n",
        "\n",
        "    # (B, 1, H_Q, Head_dim) --> (B, H_Q, 1, Head_dim)\n",
        "    xq = xq.transpose(1, 2)\n",
        "    keys = keys.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "    # (B, H_Q, 1, Head_dim) @ (B, H_Q, HEad_Dim, Seq_len_kv) --> (B, H_Q, 1, Seq_len_kv)\n",
        "    scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
        "    scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
        "    # (B, H_Q, 1, Seq_len) @ (B, H_Q, Seq_len_KV, Head_dim) --> (B, H_Q, 1, Head_dim)\n",
        "    output = torch.matmul(scores, values)\n",
        "\n",
        "    # (B, H_Q, 1, Head_dim) -> (B, 1, H_Q, Head_dim) -> (B, 1, Dim)\n",
        "    output = (output.transpose(1, 2).contiguous().view(batch_size, seq_len, -1))\n",
        "    return self.wo(output) # (B, 1, Dim) -> (B, 1, Dim)\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, args: ModelArgs) -> None:\n",
        "    super().__init__()\n",
        "    self.n_heads = args.n_heads\n",
        "    self.dim = args.dim\n",
        "    # the embedding has a dimension dim, but each head will see dim/n_heads items per token\n",
        "    self.head_dim = args.dim // args.n_heads\n",
        "\n",
        "    self.attention = SelfAttention(args)\n",
        "    self.feed_forward = FeedForward(args)\n",
        "\n",
        "    # Normalization before the self attention\n",
        "    # Look at the slides for visual:\n",
        "    # https://github.com/hkproj/pytorch-llama/blob/main/Slides.pdf\n",
        "    self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
        "    # Normalization Before the feed forward block\n",
        "    self.ffw_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor) -> torch.Tensor:\n",
        "    # (B, Seq_len, Dim) + (B, Seq_len, Dim) -> (B, Seq_len, Dim)\n",
        "    rms_norm_before_attention = self.attention_norm(x)\n",
        "    h = x + self.attention.forward(rms_norm_before_attention, start_pos, freqs_complex)\n",
        "\n",
        "    rsm_norm_before_ffw = self.ffw_norm(h)\n",
        "    out = h + self.feed_forward.forward(rsm_norm_before_ffw)\n",
        "    return out\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self, args: ModelArgs) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    assert args.vocab_size > 0, \"Vocab size must be positive\"\n",
        "\n",
        "    self.args = args\n",
        "    self.vocab_size = args.vocab_size\n",
        "    self.n_layers = args.n_layers\n",
        "    self.tok_embeddings = nn.Embedding(args.vocab_size, args.dim)\n",
        "\n",
        "    self.layers = nn.ModuleList()\n",
        "    for layer in range(args.n_layers):\n",
        "      self.layers.append(EncoderBlock(args))\n",
        "\n",
        "    # eps: epsilon is used for the normalization so we are never dividing by zero.\n",
        "    self.norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
        "    # the output is always the vocab size since we will be sampling from it.\n",
        "    # see it as a classification one from vocab_size\n",
        "    self.output = nn.Linear(args.dim, args.vocab_size, bias=False)\n",
        "\n",
        "    # frequency of the rotary positional embeddings\n",
        "    head_dim = self.args.dim // self.args.n_heads\n",
        "    seq_len = self.args.max_seq_len * 2\n",
        "    self.freqs_complex = _precompute_theta_pos_frequencies(head_dim,\n",
        "                                                           seq_len=seq_len,\n",
        "                                                           device=self.args.device)\n",
        "\n",
        "  def forward(self, tokens: torch.Tensor, start_pos: int):\n",
        "    # (batch B, seq_len)\n",
        "    batch_size, seq_len = tokens.shape\n",
        "    assert seq_len == 1, \"Only one token at a time can be processed.\"\n",
        "\n",
        "    # (B, Seq_len) -> (B, Seq_len, dim)\n",
        "    h = self.tok_embeddings(tokens)\n",
        "\n",
        "    # Retrieve the pairs (m, theta) corresponding to the positions [start_pos, start_pos + seq_len]\n",
        "    freqs_complex = self.freqs_complex[start_pos:start_pos + seq_len]\n",
        "\n",
        "    # Consecutively apply all the encoder layers blocks\n",
        "    for layer in self.layers:\n",
        "      h = layer(h, start_pos, freqs_complex)\n",
        "\n",
        "    # Normalize the output\n",
        "    h = self.norm(h)\n",
        "    output = self.output(h).float()\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "sM58W9ihO7Db"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "amSXi4rViEEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "import json\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "class LLaMA:\n",
        "  def __init__(self, model: Transformer, tokenizer: SentencePieceProcessor, model_args : ModelArgs) -> None:\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.model_args = model_args\n",
        "\n",
        "  @staticmethod\n",
        "  def build(checkpoints_dir: str, tokenizer_path: str, load_model: bool, max_seq_len: int, max_batch_size: int, device: str) -> 'LLaMA':\n",
        "    start_time = time.time()\n",
        "    if load_model:\n",
        "      checkpoints = sorted(Path(checkpoints_dir).glob('*.pth'))\n",
        "      assert len(checkpoints) > 0, f\"No checkpoints found in {checkpoints_dir}\"\n",
        "      ckpt_path = checkpoints[0]\n",
        "      print(f\"Loading model from {ckpt_path}\")\n",
        "      checkpoint = torch.load(ckpt_path, map_location='cpu',weights_only=True)\n",
        "      print(f\"Time to load model: {time.time() - start_time:.2f}\")\n",
        "      start_time = time.time()\n",
        "    with open(Path(checkpoints_dir) / 'params.json', 'r') as f:\n",
        "      params = json.loads(f.read())\n",
        "    model_args : ModelArgs = ModelArgs(\n",
        "        max_seq_len=max_seq_len,\n",
        "        max_batch_size=max_batch_size,\n",
        "        device=device,\n",
        "        **params\n",
        "    )\n",
        "    tokenizer = SentencePieceProcessor()\n",
        "    tokenizer.load(tokenizer_path)\n",
        "    model_args.vocab_size = tokenizer.vocab_size()\n",
        "\n",
        "    if device == \"cuda\":\n",
        "      torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
        "    else:\n",
        "      torch.set_default_tensor_type(torch.BFloat16Tensor)\n",
        "\n",
        "    model = Transformer(model_args).to(device)\n",
        "    if load_model:\n",
        "      del checkpoint['rope.freqs']\n",
        "      model.load_state_dict(checkpoint, strict=True)\n",
        "    print(f\"Time to load state dict in: {time.time() - start_time:.2f}\")\n",
        "    return LLaMA(model, tokenizer, model_args)\n"
      ],
      "metadata": {
        "id": "FZqiz6J9eZVF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the model\n",
        "\n",
        "In order to download the model, you need to acknowledge the usage on HF and then follow these steps:"
      ],
      "metadata": {
        "id": "V0WA0YkC211U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "0f113e7ecea742e99bd85ec602a879fb",
            "7211eafe6ff64820bcb3a759d3a1c4a0",
            "ec5ed8b977c64e67a378a54363f563ed",
            "f81961f498fe405fbfedd0f70a5c585f",
            "46bbe23c3de643f4afa9a52606ea2014",
            "c229d742ba0249d3a9d94a8983634835",
            "3ad5084f1081442e9e771d634bf6da82",
            "3004e37ca6104267bd6fa9414076fe00",
            "41740a1063f044e9baf348a91d10abd5",
            "4de431debbe14a9097ed121e1889adbe",
            "76f7f3e5913d435c9b6e04e1117c1ca9",
            "6eeb23264d6e41ada03916d4b57245aa",
            "21b6e00c4a2545f380ffb5a07f233dc7",
            "36ae0db17eab43a3ba172f7b8325ac6e",
            "6b0e90a8bcac4febaf5617e0f39701c5",
            "a792e0d21a5d4cf293d53dcef6f36f94",
            "5e6e5ae4bdfa48d3b265072e9f1ca5c3",
            "6175e2381b9b4a5ea97b160495dcb9bc",
            "50f2a9f8a57a4d33915a168089a8bdf7",
            "f31ecc7404704dde930d2895ad667667"
          ]
        },
        "id": "U9OgH3O4l39z",
        "outputId": "6ba19af3-a430-49aa-c9e4-31907c2ca254"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f113e7ecea742e99bd85ec602a879fb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_Hm3uuP0e7N",
        "outputId": "61dbc6b0-d4b4-4c9f-b729-679a38107a48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `full2` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `full2`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download meta-llama/Llama-2-7b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rriHm5wJm0WN",
        "outputId": "ed4d66f7-9519-44be-b7e4-0c939f53052e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 10 files:   0% 0/10 [00:00<?, ?it/s]Downloading 'LICENSE.txt' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/51089e27e6764fb9f72c06a0f3710699fb6c9448.incomplete'\n",
            "Downloading 'consolidated.00.pth' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/d67a91807d5879d193a694da57f28ff85092e92dc9fbef4888bd05e22b15ab75.incomplete'\n",
            "Downloading 'checklist.chk' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/510da489e04e615c1b50e690e03a62d3bbff9fd9.incomplete'\n",
            "Downloading 'Responsible-Use-Guide.pdf' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/525dc349d71fe257fce4098c146446df6fef4247174f351381e4c3214af126f0.incomplete'\n",
            "Downloading '.gitattributes' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/432012a5e6ec946e6c1cb318f256223889e3ab44.incomplete'\n",
            "Downloading 'USE_POLICY.md' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/abbcc199b2d1e4feb5d7e40c0bd67e1b0ce29e97.incomplete'\n",
            "\n",
            "LICENSE.txt: 100% 7.02k/7.02k [00:00<00:00, 45.1MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/51089e27e6764fb9f72c06a0f3710699fb6c9448\n",
            "Downloading 'README.md' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/07c67641a533e224b79958fcd38c2783a59595d0.incomplete'\n",
            "Downloading 'params.json' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/6523f76675b50e9cf3a57d1fb135189abcffe1c7.incomplete'\n",
            "\n",
            ".gitattributes: 100% 1.58k/1.58k [00:00<00:00, 16.6MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/432012a5e6ec946e6c1cb318f256223889e3ab44\n",
            "Fetching 10 files:  10% 1/10 [00:00<00:01,  7.41it/s]\n",
            "checklist.chk: 100% 100/100 [00:00<00:00, 1.01MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/510da489e04e615c1b50e690e03a62d3bbff9fd9\n",
            "\n",
            "Responsible-Use-Guide.pdf:   0% 0.00/1.25M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "USE_POLICY.md: 100% 4.77k/4.77k [00:00<00:00, 29.1MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/abbcc199b2d1e4feb5d7e40c0bd67e1b0ce29e97\n",
            "\n",
            "\n",
            "consolidated.00.pth:   0% 0.00/13.5G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "README.md: 100% 22.3k/22.3k [00:00<00:00, 50.4MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/07c67641a533e224b79958fcd38c2783a59595d0\n",
            "\n",
            "\n",
            "\n",
            "params.json: 100% 102/102 [00:00<00:00, 1.00MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/6523f76675b50e9cf3a57d1fb135189abcffe1c7\n",
            "Downloading 'tokenizer_checklist.chk' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/4531f05cde0f2f2cb2d44055cf08e1d467d40196.incomplete'\n",
            "Responsible-Use-Guide.pdf: 100% 1.25M/1.25M [00:00<00:00, 19.5MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/525dc349d71fe257fce4098c146446df6fef4247174f351381e4c3214af126f0\n",
            "\n",
            "tokenizer_checklist.chk: 100% 50.0/50.0 [00:00<00:00, 571kB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/4531f05cde0f2f2cb2d44055cf08e1d467d40196\n",
            "Downloading 'tokenizer.model' to '/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/9e556afd44213b6bd1be2b850ebbbd98f5481437a8021afaf58ee7fb1818d347.incomplete'\n",
            "\n",
            "\n",
            "consolidated.00.pth:   0% 10.5M/13.5G [00:00<02:17, 97.6MB/s]\u001b[A\u001b[A\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 10.3MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/9e556afd44213b6bd1be2b850ebbbd98f5481437a8021afaf58ee7fb1818d347\n",
            "\n",
            "\n",
            "consolidated.00.pth:   0% 41.9M/13.5G [00:00<01:12, 184MB/s] \u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   1% 73.4M/13.5G [00:00<01:00, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   1% 105M/13.5G [00:00<00:56, 238MB/s] \u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   1% 136M/13.5G [00:00<00:54, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   1% 168M/13.5G [00:00<00:54, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   1% 199M/13.5G [00:00<00:53, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   2% 231M/13.5G [00:00<00:53, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   2% 262M/13.5G [00:01<00:53, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   2% 294M/13.5G [00:01<00:51, 254MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   2% 325M/13.5G [00:01<00:52, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   3% 357M/13.5G [00:01<00:52, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   3% 388M/13.5G [00:01<00:52, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   3% 419M/13.5G [00:01<00:52, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   3% 451M/13.5G [00:01<00:52, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   4% 482M/13.5G [00:01<00:53, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   4% 514M/13.5G [00:02<00:52, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   4% 545M/13.5G [00:02<00:53, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   4% 577M/13.5G [00:02<00:52, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   5% 608M/13.5G [00:02<00:53, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   5% 640M/13.5G [00:02<00:52, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   5% 671M/13.5G [00:02<00:52, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   5% 703M/13.5G [00:02<00:52, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   5% 734M/13.5G [00:03<00:52, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   6% 765M/13.5G [00:03<00:52, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   6% 797M/13.5G [00:03<00:52, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   6% 828M/13.5G [00:03<00:52, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   6% 860M/13.5G [00:03<00:52, 239MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   7% 891M/13.5G [00:03<00:52, 240MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   7% 923M/13.5G [00:03<00:52, 240MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   7% 954M/13.5G [00:03<00:51, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   7% 986M/13.5G [00:04<00:51, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   8% 1.02G/13.5G [00:04<00:50, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   8% 1.05G/13.5G [00:04<01:02, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   8% 1.08G/13.5G [00:04<00:58, 211MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   8% 1.11G/13.5G [00:04<00:56, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   8% 1.14G/13.5G [00:04<00:54, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   9% 1.17G/13.5G [00:04<00:53, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   9% 1.21G/13.5G [00:05<00:52, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   9% 1.24G/13.5G [00:05<00:51, 238MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:   9% 1.27G/13.5G [00:05<01:07, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  10% 1.30G/13.5G [00:05<01:01, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  10% 1.33G/13.5G [00:05<00:57, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  10% 1.36G/13.5G [00:05<00:54, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  10% 1.39G/13.5G [00:05<00:53, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  11% 1.43G/13.5G [00:06<00:52, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  11% 1.46G/13.5G [00:06<00:51, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  11% 1.49G/13.5G [00:06<01:06, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  11% 1.52G/13.5G [00:06<01:01, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  12% 1.55G/13.5G [00:06<00:57, 209MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  12% 1.58G/13.5G [00:06<00:53, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  12% 1.61G/13.5G [00:07<00:52, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  12% 1.65G/13.5G [00:07<00:50, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  12% 1.68G/13.5G [00:07<01:07, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  13% 1.71G/13.5G [00:07<01:01, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  13% 1.74G/13.5G [00:07<00:57, 204MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  13% 1.77G/13.5G [00:07<00:54, 213MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  13% 1.80G/13.5G [00:07<00:52, 224MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  14% 1.84G/13.5G [00:08<00:51, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  14% 1.87G/13.5G [00:08<00:50, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  14% 1.90G/13.5G [00:08<01:04, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  14% 1.93G/13.5G [00:08<00:58, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  15% 1.96G/13.5G [00:08<00:54, 210MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  15% 1.99G/13.5G [00:08<00:52, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  15% 2.02G/13.5G [00:08<00:50, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  15% 2.06G/13.5G [00:09<00:49, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  15% 2.09G/13.5G [00:09<00:48, 237MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  16% 2.12G/13.5G [00:09<01:03, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  16% 2.15G/13.5G [00:09<00:57, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  16% 2.18G/13.5G [00:09<00:53, 210MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  16% 2.21G/13.5G [00:09<00:51, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  17% 2.24G/13.5G [00:10<00:50, 224MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  17% 2.28G/13.5G [00:10<00:49, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  17% 2.31G/13.5G [00:10<01:10, 159MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  17% 2.34G/13.5G [00:10<01:04, 173MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  18% 2.37G/13.5G [00:10<00:59, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  18% 2.40G/13.5G [00:10<00:55, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  18% 2.43G/13.5G [00:11<00:52, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  18% 2.46G/13.5G [00:11<00:50, 217MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  19% 2.50G/13.5G [00:11<00:49, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  19% 2.53G/13.5G [00:11<00:51, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  19% 2.56G/13.5G [00:11<00:49, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  19% 2.59G/13.5G [00:11<00:47, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  19% 2.62G/13.5G [00:11<00:47, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  20% 2.65G/13.5G [00:11<00:45, 237MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  20% 2.68G/13.5G [00:12<00:44, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  20% 2.72G/13.5G [00:12<00:43, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  20% 2.75G/13.5G [00:12<00:59, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  21% 2.78G/13.5G [00:12<00:54, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  21% 2.81G/13.5G [00:12<00:51, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  21% 2.84G/13.5G [00:12<00:49, 215MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  21% 2.87G/13.5G [00:13<00:46, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  22% 2.90G/13.5G [00:13<00:46, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  22% 2.94G/13.5G [00:13<00:58, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  22% 2.97G/13.5G [00:13<00:53, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  22% 3.00G/13.5G [00:13<00:50, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  22% 3.03G/13.5G [00:13<00:47, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  23% 3.06G/13.5G [00:13<00:45, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  23% 3.09G/13.5G [00:14<00:44, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  23% 3.12G/13.5G [00:14<00:43, 237MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  23% 3.16G/13.5G [00:14<00:58, 177MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  24% 3.19G/13.5G [00:14<00:53, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  24% 3.22G/13.5G [00:14<00:49, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  24% 3.25G/13.5G [00:14<00:47, 217MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  24% 3.28G/13.5G [00:14<00:44, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  25% 3.31G/13.5G [00:15<00:44, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  25% 3.34G/13.5G [00:15<00:42, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  25% 3.38G/13.5G [00:15<00:56, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  25% 3.41G/13.5G [00:15<00:51, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  26% 3.44G/13.5G [00:15<00:48, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  26% 3.47G/13.5G [00:15<00:45, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  26% 3.50G/13.5G [00:16<00:44, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  26% 3.53G/13.5G [00:16<00:42, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  26% 3.57G/13.5G [00:16<00:56, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  27% 3.60G/13.5G [00:16<00:51, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  27% 3.63G/13.5G [00:16<00:48, 203MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  27% 3.66G/13.5G [00:16<00:45, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  27% 3.69G/13.5G [00:16<00:44, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  28% 3.72G/13.5G [00:17<00:43, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  28% 3.75G/13.5G [00:17<00:41, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  28% 3.79G/13.5G [00:17<00:53, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  28% 3.82G/13.5G [00:17<00:48, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  29% 3.85G/13.5G [00:17<00:45, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  29% 3.88G/13.5G [00:17<00:42, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  29% 3.91G/13.5G [00:17<00:41, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  29% 3.94G/13.5G [00:18<00:40, 237MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  29% 3.97G/13.5G [00:18<00:39, 238MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  30% 4.01G/13.5G [00:18<00:53, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  30% 4.04G/13.5G [00:18<00:48, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  30% 4.07G/13.5G [00:18<00:45, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  30% 4.10G/13.5G [00:18<00:43, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  31% 4.13G/13.5G [00:19<00:41, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  31% 4.16G/13.5G [00:19<00:40, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  31% 4.19G/13.5G [00:19<00:53, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  31% 4.23G/13.5G [00:19<00:47, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  32% 4.26G/13.5G [00:19<00:44, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  32% 4.29G/13.5G [00:19<00:43, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  32% 4.32G/13.5G [00:19<00:41, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  32% 4.35G/13.5G [00:20<00:40, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  33% 4.38G/13.5G [00:20<00:38, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  33% 4.41G/13.5G [00:20<00:50, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  33% 4.45G/13.5G [00:20<00:46, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  33% 4.48G/13.5G [00:20<00:43, 209MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  33% 4.51G/13.5G [00:20<00:45, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  34% 4.54G/13.5G [00:21<00:42, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  34% 4.57G/13.5G [00:21<00:40, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  34% 4.60G/13.5G [00:21<00:39, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  34% 4.63G/13.5G [00:21<00:46, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  35% 4.67G/13.5G [00:21<00:42, 205MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  35% 4.70G/13.5G [00:21<00:40, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  35% 4.73G/13.5G [00:21<00:39, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  35% 4.76G/13.5G [00:22<00:38, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  36% 4.79G/13.5G [00:22<00:37, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  36% 4.82G/13.5G [00:22<00:48, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  36% 4.85G/13.5G [00:22<00:44, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  36% 4.89G/13.5G [00:22<00:41, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  36% 4.92G/13.5G [00:22<00:39, 216MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  37% 4.95G/13.5G [00:22<00:37, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  37% 4.98G/13.5G [00:23<00:37, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  37% 5.01G/13.5G [00:23<00:35, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  37% 5.04G/13.5G [00:23<00:46, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  38% 5.08G/13.5G [00:23<00:42, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  38% 5.11G/13.5G [00:23<00:40, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  38% 5.14G/13.5G [00:23<00:38, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  38% 5.17G/13.5G [00:23<00:36, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  39% 5.20G/13.5G [00:24<00:35, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  39% 5.23G/13.5G [00:24<00:34, 239MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  39% 5.26G/13.5G [00:24<00:46, 177MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  39% 5.30G/13.5G [00:24<00:42, 194MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  40% 5.33G/13.5G [00:24<00:39, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  40% 5.36G/13.5G [00:24<00:37, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  40% 5.39G/13.5G [00:25<00:35, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  40% 5.42G/13.5G [00:25<00:35, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  40% 5.45G/13.5G [00:25<00:45, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  41% 5.48G/13.5G [00:25<00:41, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  41% 5.52G/13.5G [00:25<00:38, 205MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  41% 5.55G/13.5G [00:25<00:36, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  41% 5.58G/13.5G [00:25<00:34, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  42% 5.61G/13.5G [00:26<00:34, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  42% 5.64G/13.5G [00:26<00:33, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  42% 5.67G/13.5G [00:26<00:43, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  42% 5.70G/13.5G [00:26<00:39, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  43% 5.74G/13.5G [00:26<00:37, 209MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  43% 5.77G/13.5G [00:26<00:35, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  43% 5.80G/13.5G [00:26<00:33, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  43% 5.83G/13.5G [00:27<00:32, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  43% 5.86G/13.5G [00:27<00:31, 239MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  44% 5.89G/13.5G [00:27<00:43, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  44% 5.92G/13.5G [00:27<00:39, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  44% 5.96G/13.5G [00:27<00:36, 209MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  44% 5.99G/13.5G [00:27<00:34, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  45% 6.02G/13.5G [00:28<00:33, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  45% 6.05G/13.5G [00:28<00:31, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  45% 6.08G/13.5G [00:28<00:42, 174MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  45% 6.11G/13.5G [00:28<00:38, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  46% 6.14G/13.5G [00:28<00:36, 202MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  46% 6.18G/13.5G [00:28<00:34, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  46% 6.21G/13.5G [00:28<00:32, 223MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  46% 6.24G/13.5G [00:29<00:33, 213MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  47% 6.27G/13.5G [00:29<00:32, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  47% 6.30G/13.5G [00:29<00:38, 186MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  47% 6.33G/13.5G [00:29<00:35, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  47% 6.36G/13.5G [00:29<00:33, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  47% 6.40G/13.5G [00:29<00:31, 224MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  48% 6.43G/13.5G [00:29<00:31, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  48% 6.46G/13.5G [00:30<00:30, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  48% 6.49G/13.5G [00:30<00:29, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  48% 6.52G/13.5G [00:30<00:38, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  49% 6.55G/13.5G [00:30<00:35, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  49% 6.59G/13.5G [00:30<00:32, 209MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  49% 6.62G/13.5G [00:31<00:44, 153MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  49% 6.65G/13.5G [00:31<00:40, 170MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  50% 6.68G/13.5G [00:31<00:36, 186MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  50% 6.71G/13.5G [00:31<00:33, 202MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  50% 6.74G/13.5G [00:31<00:31, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  50% 6.77G/13.5G [00:31<00:30, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  50% 6.81G/13.5G [00:31<00:29, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  51% 6.84G/13.5G [00:32<00:28, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  51% 6.87G/13.5G [00:32<00:28, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  51% 6.90G/13.5G [00:32<00:27, 238MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  51% 6.93G/13.5G [00:32<00:31, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  52% 6.96G/13.5G [00:32<00:29, 217MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  52% 6.99G/13.5G [00:32<00:29, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  52% 7.03G/13.5G [00:32<00:28, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  52% 7.06G/13.5G [00:32<00:27, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  53% 7.09G/13.5G [00:33<00:27, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  53% 7.12G/13.5G [00:33<00:26, 239MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  53% 7.15G/13.5G [00:33<00:34, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  53% 7.18G/13.5G [00:33<00:31, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  54% 7.21G/13.5G [00:33<00:30, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  54% 7.25G/13.5G [00:33<00:28, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  54% 7.28G/13.5G [00:34<00:27, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  54% 7.31G/13.5G [00:34<00:26, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  54% 7.34G/13.5G [00:34<00:34, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  55% 7.37G/13.5G [00:34<00:31, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  55% 7.40G/13.5G [00:34<00:29, 204MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  55% 7.43G/13.5G [00:34<00:28, 216MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  55% 7.47G/13.5G [00:34<00:27, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  56% 7.50G/13.5G [00:35<00:25, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  56% 7.53G/13.5G [00:35<00:25, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  56% 7.56G/13.5G [00:35<00:32, 183MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  56% 7.59G/13.5G [00:35<00:29, 199MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  57% 7.62G/13.5G [00:35<00:27, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  57% 7.65G/13.5G [00:35<00:26, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  57% 7.69G/13.5G [00:35<00:25, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  57% 7.72G/13.5G [00:36<00:24, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  57% 7.75G/13.5G [00:36<00:24, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  58% 7.78G/13.5G [00:36<00:31, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  58% 7.81G/13.5G [00:36<00:28, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  58% 7.84G/13.5G [00:36<00:26, 210MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  58% 7.87G/13.5G [00:36<00:25, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  59% 7.91G/13.5G [00:37<00:23, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  59% 7.94G/13.5G [00:37<00:23, 239MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  59% 7.97G/13.5G [00:37<00:31, 173MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  59% 8.00G/13.5G [00:37<00:29, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  60% 8.03G/13.5G [00:37<00:27, 201MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  60% 8.06G/13.5G [00:37<00:25, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  60% 8.10G/13.5G [00:37<00:26, 203MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  60% 8.13G/13.5G [00:38<00:25, 211MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  61% 8.16G/13.5G [00:38<00:23, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  61% 8.19G/13.5G [00:38<00:27, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  61% 8.22G/13.5G [00:38<00:25, 204MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  61% 8.25G/13.5G [00:38<00:24, 215MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  61% 8.28G/13.5G [00:38<00:23, 224MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  62% 8.32G/13.5G [00:38<00:22, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  62% 8.35G/13.5G [00:39<00:22, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  62% 8.38G/13.5G [00:39<00:21, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  62% 8.41G/13.5G [00:39<00:28, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  63% 8.44G/13.5G [00:39<00:25, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  63% 8.47G/13.5G [00:39<00:23, 209MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  63% 8.50G/13.5G [00:39<00:23, 215MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  63% 8.54G/13.5G [00:40<00:22, 223MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  64% 8.57G/13.5G [00:40<00:21, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  64% 8.60G/13.5G [00:40<00:27, 178MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  64% 8.63G/13.5G [00:40<00:25, 194MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  64% 8.66G/13.5G [00:40<00:23, 206MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  65% 8.69G/13.5G [00:40<00:21, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  65% 8.72G/13.5G [00:41<00:27, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  65% 8.75G/13.5G [00:41<00:54, 86.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  65% 8.77G/13.5G [00:42<01:07, 70.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  65% 8.79G/13.5G [00:42<00:56, 82.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  65% 8.82G/13.5G [00:42<00:43, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  66% 8.85G/13.5G [00:42<00:35, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  66% 8.88G/13.5G [00:42<00:29, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  66% 8.90G/13.5G [00:43<00:36, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  66% 8.92G/13.5G [00:43<01:06, 68.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  66% 8.94G/13.5G [00:44<01:12, 62.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  67% 8.98G/13.5G [00:44<00:52, 85.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  67% 9.01G/13.5G [00:44<00:40, 111MB/s] \u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  67% 9.04G/13.5G [00:44<00:32, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  67% 9.07G/13.5G [00:44<00:27, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  68% 9.10G/13.5G [00:44<00:24, 178MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  68% 9.13G/13.5G [00:44<00:22, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  68% 9.16G/13.5G [00:45<00:20, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  68% 9.20G/13.5G [00:45<00:19, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  68% 9.23G/13.5G [00:45<00:18, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  69% 9.26G/13.5G [00:45<00:17, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  69% 9.29G/13.5G [00:45<00:17, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  69% 9.32G/13.5G [00:45<00:17, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  69% 9.35G/13.5G [00:45<00:16, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  70% 9.38G/13.5G [00:45<00:16, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  70% 9.42G/13.5G [00:46<00:16, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  70% 9.45G/13.5G [00:46<00:16, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  70% 9.48G/13.5G [00:46<00:16, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  71% 9.51G/13.5G [00:46<00:16, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  71% 9.54G/13.5G [00:46<00:16, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  71% 9.57G/13.5G [00:46<00:16, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  71% 9.60G/13.5G [00:46<00:15, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  72% 9.64G/13.5G [00:46<00:15, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  72% 9.67G/13.5G [00:47<00:15, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  72% 9.70G/13.5G [00:47<00:15, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  72% 9.73G/13.5G [00:47<00:15, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  72% 9.76G/13.5G [00:47<00:15, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  73% 9.79G/13.5G [00:47<00:15, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  73% 9.83G/13.5G [00:47<00:15, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  73% 9.86G/13.5G [00:47<00:14, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  73% 9.89G/13.5G [00:47<00:14, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  74% 9.92G/13.5G [00:48<00:14, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  74% 9.95G/13.5G [00:48<00:14, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  74% 9.98G/13.5G [00:48<00:14, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  74% 10.0G/13.5G [00:48<00:14, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  75% 10.0G/13.5G [00:48<00:14, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  75% 10.1G/13.5G [00:48<00:13, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  75% 10.1G/13.5G [00:48<00:13, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  75% 10.1G/13.5G [00:49<00:13, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  75% 10.2G/13.5G [00:49<00:13, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  76% 10.2G/13.5G [00:49<00:13, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  76% 10.2G/13.5G [00:49<00:13, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  76% 10.3G/13.5G [00:49<00:13, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  76% 10.3G/13.5G [00:49<00:13, 238MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  77% 10.3G/13.5G [00:49<00:13, 240MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  77% 10.4G/13.5G [00:49<00:12, 240MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  77% 10.4G/13.5G [00:50<00:12, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  77% 10.4G/13.5G [00:50<00:12, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  78% 10.5G/13.5G [00:50<00:12, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  78% 10.5G/13.5G [00:50<00:12, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  78% 10.5G/13.5G [00:50<00:11, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  78% 10.5G/13.5G [00:50<00:11, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  79% 10.6G/13.5G [00:50<00:11, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  79% 10.6G/13.5G [00:50<00:11, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  79% 10.6G/13.5G [00:51<00:11, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  79% 10.7G/13.5G [00:51<00:11, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  79% 10.7G/13.5G [00:51<00:11, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  80% 10.7G/13.5G [00:51<00:10, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  80% 10.8G/13.5G [00:51<00:10, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  80% 10.8G/13.5G [00:51<00:10, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  80% 10.8G/13.5G [00:51<00:10, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  81% 10.9G/13.5G [00:51<00:10, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  81% 10.9G/13.5G [00:52<00:10, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  81% 10.9G/13.5G [00:52<00:10, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  81% 11.0G/13.5G [00:52<00:10, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  82% 11.0G/13.5G [00:52<00:10, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  82% 11.0G/13.5G [00:52<00:10, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  82% 11.1G/13.5G [00:52<00:09, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  82% 11.1G/13.5G [00:52<00:09, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  82% 11.1G/13.5G [00:52<00:09, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  83% 11.1G/13.5G [00:53<00:09, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  83% 11.2G/13.5G [00:53<00:09, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  83% 11.2G/13.5G [00:53<00:09, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  83% 11.2G/13.5G [00:53<00:09, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  84% 11.3G/13.5G [00:53<00:09, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  84% 11.3G/13.5G [00:53<00:08, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  84% 11.3G/13.5G [00:53<00:08, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  84% 11.4G/13.5G [00:54<00:08, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  85% 11.4G/13.5G [00:54<00:08, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  85% 11.4G/13.5G [00:54<00:08, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  85% 11.5G/13.5G [00:54<00:08, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  85% 11.5G/13.5G [00:54<00:08, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  86% 11.5G/13.5G [00:54<00:07, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  86% 11.6G/13.5G [00:54<00:07, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  86% 11.6G/13.5G [00:54<00:07, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  86% 11.6G/13.5G [00:55<00:07, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  86% 11.6G/13.5G [00:55<00:07, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  87% 11.7G/13.5G [00:55<00:07, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  87% 11.7G/13.5G [00:55<00:07, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  87% 11.7G/13.5G [00:55<00:07, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  87% 11.8G/13.5G [00:55<00:07, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  88% 11.8G/13.5G [00:55<00:06, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  88% 11.8G/13.5G [00:55<00:06, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  88% 11.9G/13.5G [00:56<00:06, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  88% 11.9G/13.5G [00:56<00:07, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  89% 11.9G/13.5G [00:56<00:07, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  89% 12.0G/13.5G [00:56<00:06, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  89% 12.0G/13.5G [00:56<00:06, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  89% 12.0G/13.5G [00:56<00:05, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  89% 12.1G/13.5G [00:56<00:05, 253MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  90% 12.1G/13.5G [00:57<00:05, 254MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  90% 12.1G/13.5G [00:57<00:05, 256MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  90% 12.2G/13.5G [00:57<00:07, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  90% 12.2G/13.5G [00:57<00:09, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.2G/13.5G [00:58<00:11, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.2G/13.5G [00:58<00:18, 69.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.2G/13.5G [00:59<00:21, 56.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.3G/13.5G [00:59<00:22, 54.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.3G/13.5G [01:00<00:25, 47.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.3G/13.5G [01:00<00:29, 40.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.3G/13.5G [01:01<00:36, 32.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.3G/13.5G [01:01<00:44, 26.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.3G/13.5G [01:02<00:44, 25.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  91% 12.3G/13.5G [01:02<00:42, 26.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.3G/13.5G [01:03<00:44, 25.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.4G/13.5G [01:03<00:55, 20.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.4G/13.5G [01:04<01:09, 16.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.4G/13.5G [01:06<01:31, 12.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.4G/13.5G [01:08<02:15, 8.08MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.4G/13.5G [01:11<03:03, 5.89MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.4G/13.5G [01:14<03:30, 5.09MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.4G/13.5G [01:16<03:25, 5.18MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.4G/13.5G [01:17<02:50, 6.18MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  92% 12.5G/13.5G [01:17<01:14, 13.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  93% 12.5G/13.5G [01:17<00:49, 20.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  93% 12.5G/13.5G [01:17<00:29, 33.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  93% 12.5G/13.5G [01:17<00:18, 49.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  93% 12.6G/13.5G [01:17<00:13, 68.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  94% 12.6G/13.5G [01:17<00:09, 90.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  94% 12.6G/13.5G [01:17<00:07, 113MB/s] \u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  94% 12.7G/13.5G [01:18<00:05, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  94% 12.7G/13.5G [01:18<00:04, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  94% 12.7G/13.5G [01:18<00:04, 177MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  95% 12.8G/13.5G [01:18<00:03, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  95% 12.8G/13.5G [01:18<00:03, 206MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  95% 12.8G/13.5G [01:19<00:04, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  95% 12.8G/13.5G [01:19<00:04, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  96% 12.9G/13.5G [01:19<00:03, 152MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  96% 12.9G/13.5G [01:19<00:04, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  96% 12.9G/13.5G [01:19<00:04, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  96% 13.0G/13.5G [01:20<00:04, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  96% 13.0G/13.5G [01:20<00:03, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  97% 13.0G/13.5G [01:20<00:03, 114MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  97% 13.1G/13.5G [01:21<00:03, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  97% 13.1G/13.5G [01:21<00:04, 98.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  97% 13.1G/13.5G [01:21<00:04, 90.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  97% 13.1G/13.5G [01:21<00:02, 119MB/s] \u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  98% 13.2G/13.5G [01:21<00:02, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  98% 13.2G/13.5G [01:22<00:02, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  98% 13.2G/13.5G [01:22<00:02, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  98% 13.2G/13.5G [01:22<00:01, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  98% 13.3G/13.5G [01:22<00:01, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  99% 13.3G/13.5G [01:23<00:01, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  99% 13.3G/13.5G [01:23<00:01, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  99% 13.4G/13.5G [01:23<00:00, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth:  99% 13.4G/13.5G [01:23<00:00, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth: 100% 13.4G/13.5G [01:23<00:00, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth: 100% 13.4G/13.5G [01:24<00:00, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "consolidated.00.pth: 100% 13.5G/13.5G [01:24<00:00, 159MB/s]\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/blobs/d67a91807d5879d193a694da57f28ff85092e92dc9fbef4888bd05e22b15ab75\n",
            "Fetching 10 files: 100% 10/10 [01:24<00:00,  8.48s/it]\n",
            "/root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/snapshots/69656aac4cb47911a639f5890ff35b41ceb82e98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./llama-2-7b"
      ],
      "metadata": {
        "id": "0BBKCohsprH9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b/snapshots/69656aac4cb47911a639f5890ff35b41ceb82e98/* ./llama-2-7b/"
      ],
      "metadata": {
        "id": "bzXa49VJnOyH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints_dir = \"/content/llama-2-7b\"\n",
        "checkpoints = sorted(Path(checkpoints_dir).glob('*.pth'))\n",
        "for c in checkpoints:\n",
        "  print(c)\n",
        "assert len(checkpoints) > 0, f\"No checkpoints found in {checkpoints_dir}\"\n",
        "# from huggingface_hub import snapshot_download\n",
        "# snapshot_download(repo_id=\"meta-llama/Llama-2-7b\", local_dir=local_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EbZddwGBdHj",
        "outputId": "b0f84656-d788-4fa5-f3b5-88e0e09a6de3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llama-2-7b/consolidated.00.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a /content/llama-2-7b/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA_z6q41oMdp",
        "outputId": "d07e649b-7010-4f83-c3e2-ffd4e5d7c348"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\t       consolidated.00.pth  README.md\t\t       tokenizer.model\n",
            "..\t       LICENSE.txt\t    Responsible-Use-Guide.pdf  USE_POLICY.md\n",
            "checklist.chk  params.json\t    tokenizer_checklist.chk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = LLaMA.build(checkpoints_dir=\"/content/llama-2-7b/\", tokenizer_path='tokenizer.model', load_model=True, max_seq_len=1024, max_batch_size=3, device=device)"
      ],
      "metadata": {
        "id": "9HdzoyVuiWR8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "e1da8fd0-808b-4a17-f7c4-7aa16e969d0f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/llama-2-7b/consolidated.00.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/llama-2-7b/consolidated.00.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0c365b13b49f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLaMA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/llama-2-7b/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tokenizer.model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-c47ea0103be2>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(checkpoints_dir, tokenizer_path, load_model, max_seq_len, max_batch_size, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading model from {ckpt_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time to load model: {time.time() - start_time:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/llama-2-7b/consolidated.00.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\"\"]\n",
        "\n",
        "# Inference of the model"
      ],
      "metadata": {
        "id": "bGZtXCK3lllf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}